{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa5CC2r1JoBxsGHXEuOf0m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/importYM/proposal/blob/main/NWPPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Pandas import & data load**\n",
        "* pandas import\n",
        "* csv file read\n",
        "* data print"
      ],
      "metadata": {
        "id": "_Z2oPKQSDikl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bdymyt6DGXp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "\n",
        "data = pd.read_csv('/content/sample_221212_4.csv') # read csv file \n",
        "data.columns, data, data.shape[1]"
      ],
      "metadata": {
        "id": "gpl_keU2DphU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Divide to data_x, data_y**"
      ],
      "metadata": {
        "id": "1JvXgVLlD_KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = data\n",
        "data2.set_index('TIME', inplace=True) # Change the index to be based on the 'TIME' column\n",
        "\n",
        "data_x = data2.iloc[:,0:]             # data_x = nursing workload proxies grade, ID, Biomarker, Hospital demographic data \n",
        "data_y = data2.iloc[:,0:2]            # data_y = nursing workload proxies grade, ID\n",
        "\n",
        "data_x, data_y"
      ],
      "metadata": {
        "id": "yus9qmgvEAZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Setting the Maximum Data Length (hospital day 30)**"
      ],
      "metadata": {
        "id": "jts3zDUlG18f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_x에 대하여\n",
        "\n",
        "data_x_pad = pd.DataFrame(columns=data_x.columns)              # 빈 데이터프레임 생성\n",
        "\n",
        "for id in data_x['ID'].unique():                               # 각 인덱스별로 루프를 돌면서 ID마다 행 수를 맞추기 위한 for문\n",
        "    rows = data_x[data_x['ID'] == id]\n",
        "    n_rows = len(rows)\n",
        "    n_padding_rows = (30 - n_rows % 30) % 30                   # 30의 배수가 되도록 패딩할 행의 수 계산\n",
        "    padding_rows = pd.DataFrame({'ID': [id] * n_padding_rows,\n",
        "                                 'G3': [0] * n_padding_rows,\n",
        "                                 'F1': [0] * n_padding_rows,\n",
        "                                 'F2': [0] * n_padding_rows,\n",
        "                                 'F3': [0] * n_padding_rows})  # 패딩할 행의 값은 0으로 설정\n",
        "    new_rows = pd.concat([rows, padding_rows])\n",
        "    new_rows = new_rows.iloc[:30]                              # 인덱스별로 최대 30개의 행만 남기고 나머지는 버림\n",
        "    data_x_pad = pd.concat([data_x_pad, new_rows])\n",
        "\n",
        "# 결과 확인\n",
        "print(data_x_pad)"
      ],
      "metadata": {
        "id": "D1TULoEFIBJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_y에 대하여\n",
        "\n",
        "data_y_pad = pd.DataFrame(columns=data_y.columns)              # 빈 데이터프레임 생성\n",
        "\n",
        "\n",
        "for id in data_y['ID'].unique():                               # 각 인덱스별로 루프를 돌면서 ID마다 행 수를 맞추기 위한 for문\n",
        "    rows = data_y[data_y['ID'] == id]\n",
        "    n_rows = len(rows)\n",
        "    n_padding_rows = (30 - n_rows % 30) % 30                   # 30의 배수가 되도록 패딩할 행의 수 계산\n",
        "    padding_rows = pd.DataFrame({'ID': [id] * n_padding_rows,\n",
        "                                 'G3': [0] * n_padding_rows})  # 패딩할 행의 값은 0으로 설정\n",
        "    new_rows = pd.concat([rows, padding_rows])\n",
        "    new_rows = new_rows.iloc[:30]                              # 인덱스별로 최대 30개의 행만 남기고 나머지는 버림\n",
        "    data_y_pad = pd.concat([data_y_pad, new_rows])\n",
        "\n",
        "# 결과 확인\n",
        "print(data_y_pad)"
      ],
      "metadata": {
        "id": "Gx4PlUOuJNsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Change Pandas DataFrame to Numpy array**"
      ],
      "metadata": {
        "id": "SOpJANG0JyW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = data_x_pad.values     # Change Pandas DataFrame to Numpy array\n",
        "y = data_y_pad.values     # Change Pandas DataFrame to Numpy array\n",
        "print(x, y)"
      ],
      "metadata": {
        "id": "fEDQM-QNJzAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, y.shape          # x, y shape 확인 = 2D array"
      ],
      "metadata": {
        "id": "XiL-hN76J3Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Normalization feature scaling**"
      ],
      "metadata": {
        "id": "gftfsSFRKA2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "x_without_col0_1 = np.delete(x, [0, 1], axis=1)                         # delete column(nursing workload proxies grade, ID)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))                             # scaler setting\n",
        "x_normalized = scaler.fit_transform(x_without_col0_1)                   # scaler fit\n",
        "\n",
        "x_normalized_with_all = np.insert(x_normalized, [0], x[:, :2], axis=1)  # add column(nursing workload proxies grade, ID)\n",
        "\n",
        "x_normalized_with_all"
      ],
      "metadata": {
        "id": "-vXqJes6KFtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Add NaN row**"
      ],
      "metadata": {
        "id": "n1b6bDdaKyju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x_normalized_with_all 에서\n",
        "\n",
        "x_id = x_normalized_with_all[:, 1]                                  # ID열 추출\n",
        "x_other_id = np.where(x_id[:-1] != x_id[1:])[0] + 1                 # ID가 바뀌는 인덱스 확인\n",
        "\n",
        "NaN_x_row = np.full((1, n_x_col), np.nan)                           # 2D array x에 삽입할 NaN 행 생성\n",
        "X = np.insert(x_normalized_with_all, x_other_id, NaN_x_row, axis=0) # 2D 배열에 ID가 바뀌는 행마다 NaN 값을 가진 행 삽입\n",
        "\n",
        "print(X)"
      ],
      "metadata": {
        "id": "GTdhR-imKy12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y 에서\n",
        "\n",
        "y_id = y[:, 1]                                      # ID열 추출\n",
        "y_new_id = np.where(y_id[:-1] != y_id[1:])[0] + 1   # ID가 바뀌는 인덱스 확인\n",
        "\n",
        "NaN_y_row = np.full((1, n_y_col), np.nan)           # 2D array y에 삽입할 NaN 행 생성\n",
        "Y = np.insert(y, y_new_id, NaN_x_row, axis=0)       # 2D 배열에 ID가 바뀌는 행마다 NaN 값을 가진 행 삽입\n",
        "\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "_PHfXhncLgp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}